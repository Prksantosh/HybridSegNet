{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8138a625-f781-4b6e-9f82-09657f5288c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, **kwargs):\n",
    "        super().__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.padding != 0:\n",
    "            x = F.pad(x, (self.padding, 0))\n",
    "        return self.conv(x)\n",
    "\n",
    "class SelectiveSSM(nn.Module):\n",
    "    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_state = d_state\n",
    "        self.d_conv = d_conv\n",
    "        self.expand = expand\n",
    "        self.d_inner = int(self.expand * self.d_model)\n",
    "        \n",
    "        # Projections\n",
    "        self.in_proj = nn.Linear(d_model, self.d_inner * 2, bias=False)\n",
    "        self.conv1d = CausalConv1d(self.d_inner, self.d_inner, self.d_conv)\n",
    "        \n",
    "        # SSM parameters\n",
    "        self.A_log = nn.Parameter(torch.log(torch.randn(self.d_inner, self.d_state)))\n",
    "        self.D = nn.Parameter(torch.ones(self.d_inner))\n",
    "        self.out_proj = nn.Linear(self.d_inner, d_model, bias=False)\n",
    "        \n",
    "        # Selective parameters\n",
    "        self.dt_proj = nn.Linear(self.d_inner, self.d_inner)\n",
    "        self.B_proj = nn.Linear(self.d_inner, self.d_state, bias=False)\n",
    "        self.C_proj = nn.Linear(self.d_inner, self.d_state, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch, seq_len, _ = x.shape\n",
    "        \n",
    "        # Project input\n",
    "        xz = self.in_proj(x)\n",
    "        x, z = xz.chunk(2, dim=-1)\n",
    "        \n",
    "        # Conv step\n",
    "        x = rearrange(x, 'b l d -> b d l')\n",
    "        x = self.conv1d(x)\n",
    "        x = rearrange(x, 'b d l -> b l d')\n",
    "        \n",
    "        # Discretization\n",
    "        dt = self.dt_proj(x)\n",
    "        dt = torch.sigmoid(dt)\n",
    "        \n",
    "        A = -torch.exp(self.A_log.float())\n",
    "        B = self.B_proj(x)\n",
    "        C = self.C_proj(x)\n",
    "        \n",
    "        # Selective scan\n",
    "        y = self.selective_scan(x, dt, A, B, C, self.D)\n",
    "        \n",
    "        # Gating and output\n",
    "        y = y * F.silu(z)\n",
    "        return self.out_proj(y)\n",
    "    \n",
    "    def selective_scan(self, u, delta, A, B, C, D):\n",
    "        batch, seq_len, d_inner = u.shape\n",
    "        d_state = A.shape[-1]\n",
    "        \n",
    "        # Proper broadcasting shapes\n",
    "        delta = delta.unsqueeze(-1)  # (b, l, d_inner, 1)\n",
    "        A = A.view(1, 1, d_inner, d_state)  # (1, 1, d_inner, d_state)\n",
    "        B = B.unsqueeze(2)  # (b, l, 1, d_state)\n",
    "        C = C.unsqueeze(2)  # (b, l, 1, d_state)\n",
    "        \n",
    "        # Discretize\n",
    "        deltaA = torch.exp(delta * A)\n",
    "        deltaB = delta * B * u.unsqueeze(-1)  # (b, l, d_inner, d_state)\n",
    "        \n",
    "        # Initialize state\n",
    "        state = torch.zeros(batch, d_inner, d_state, device=u.device)\n",
    "        outputs = []\n",
    "        \n",
    "        # Recurrent scan\n",
    "        for i in range(seq_len):\n",
    "            state = deltaA[:, i] * state + deltaB[:, i]\n",
    "            output = torch.einsum('bdn,bdn->bd', state, C[:, i])\n",
    "            outputs.append(output + D * u[:, i])\n",
    "        \n",
    "        return torch.stack(outputs, dim=1)\n",
    "\n",
    "class DirectionalScan(nn.Module):\n",
    "    def __init__(self, ssm_layer, d_model):\n",
    "        super().__init__()\n",
    "        self.ssm_layer = ssm_layer\n",
    "        self.d_model = d_model\n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, x, h, w):\n",
    "        b, l, d = x.shape\n",
    "        assert l == h * w\n",
    "        \n",
    "        # Horizontal scans\n",
    "        x_h = rearrange(x, 'b (h w) d -> (b w) h d', h=h, w=w)\n",
    "        x_h = self.ssm_layer(x_h)\n",
    "        x_h = rearrange(x_h, '(b w) h d -> b (h w) d', h=h, w=w)\n",
    "        \n",
    "        # Vertical scans\n",
    "        x_v = rearrange(x, 'b (h w) d -> (b h) w d', h=h, w=w)\n",
    "        x_v = self.ssm_layer(x_v)\n",
    "        x_v = rearrange(x_v, '(b h) w d -> b (h w) d', h=h, w=w)\n",
    "        \n",
    "        return self.proj(x_h + x_v)\n",
    "\n",
    "class VisionMambaBlock(nn.Module):\n",
    "    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.ssm = SelectiveSSM(d_model, d_state, d_conv, expand)\n",
    "        self.scan = DirectionalScan(self.ssm, d_model)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model * 4, d_model)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, h, w):\n",
    "        x = x + self.scan(self.norm(x), h, w)\n",
    "        x = x + self.mlp(self.norm(x))\n",
    "        return x\n",
    "\n",
    "class PatchEmbed2D(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.img_size = (img_size, img_size)\n",
    "        self.patch_size = (patch_size, patch_size)\n",
    "        self.num_patches = (img_size // patch_size) ** 2\n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        return rearrange(x, 'b d h w -> b (h w) d')\n",
    "\n",
    "class VisionMamba(nn.Module):\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, \n",
    "                 num_classes=1000, embed_dim=768, depth=4, \n",
    "                 d_state=16, d_conv=4, expand=2):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbed2D(img_size, patch_size, in_chans, embed_dim)\n",
    "        self.pos_drop = nn.Dropout(p=0.1)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            VisionMambaBlock(embed_dim, d_state, d_conv, expand)\n",
    "            for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        b, l, d = x.shape\n",
    "        h = w = int(l ** 0.5)\n",
    "        x = self.pos_drop(x)\n",
    "        \n",
    "        for blk in self.blocks:\n",
    "            x = blk(x, h, w)\n",
    "        \n",
    "        x = self.norm(x.mean(dim=1))\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0a06362-8916-4859-b876-b8c4baaa102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "import numpy as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def print_model_summary(model, input_size=(3, 224, 224)):\n",
    "    # Move model to CUDA if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Create sample input on same device\n",
    "    x = torch.randn(1, *input_size).to(device)\n",
    "    \n",
    "    # Print standard summary\n",
    "    try:\n",
    "        from torchsummary import summary\n",
    "        summary(model, input_size=input_size)\n",
    "    except ImportError:\n",
    "        print(\"torchsummary not installed, install with: pip install torchsummary\")\n",
    "    \n",
    "    # Create dimension table\n",
    "    dimension_table = []\n",
    "    \n",
    "    # Track forward pass\n",
    "    with torch.no_grad():\n",
    "        dimension_table.append({\n",
    "            'Layer': 'Input',\n",
    "            'Input Shape': '-',\n",
    "            'Output Shape': str(tuple(x.shape))\n",
    "        })\n",
    "        \n",
    "        # Patch Embedding\n",
    "        x = model.patch_embed(x)\n",
    "        dimension_table.append({\n",
    "            'Layer': 'PatchEmbed',\n",
    "            'Input Shape': dimension_table[-1]['Output Shape'],\n",
    "            'Output Shape': str(tuple(x.shape))\n",
    "        })\n",
    "        \n",
    "        # Blocks\n",
    "        b, l, d = x.shape\n",
    "        h = w = int(l ** 0.5)\n",
    "        x = model.pos_drop(x)\n",
    "        \n",
    "        for i, blk in enumerate(model.blocks):\n",
    "            x_in = x\n",
    "            x = blk(x, h, w)\n",
    "            dimension_table.append({\n",
    "                'Layer': f'MambaBlock_{i+1}',\n",
    "                'Input Shape': str(tuple(x_in.shape)),\n",
    "                'Output Shape': str(tuple(x.shape))\n",
    "            })\n",
    "        \n",
    "        # Final layers\n",
    "        x = model.norm(x.mean(dim=1))\n",
    "        x = model.head(x)\n",
    "        dimension_table.append({\n",
    "            'Layer': 'Norm+Head',\n",
    "            'Input Shape': dimension_table[-1]['Output Shape'],\n",
    "            'Output Shape': str(tuple(x.shape))\n",
    "        })\n",
    "    \n",
    "    # Print formatted table\n",
    "    print(\"\\nLayer Dimension Flow:\")\n",
    "    print(tabulate(dimension_table, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "739dfd88-2bfa-42e3-8f8b-edc75b9d6838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "model = VisionMamba(\n",
    "    img_size=224,\n",
    "    patch_size=16,\n",
    "    num_classes=1000,\n",
    "    embed_dim=768,\n",
    "    depth=12,\n",
    "    d_state=16\n",
    ")\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "out = model(x)\n",
    "print(out.shape)  # Should be torch.Size([1, 1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e87f34d-3abc-44d9-acbb-2879fdb82495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
      "      PatchEmbed2D-2             [-1, 196, 768]               0\n",
      "           Dropout-3             [-1, 196, 768]               0\n",
      "         LayerNorm-4             [-1, 196, 768]           1,536\n",
      "            Linear-5             [-1, 14, 3072]       2,359,296\n",
      "            Linear-6             [-1, 14, 3072]       2,359,296\n",
      "            Conv1d-7             [-1, 1536, 14]       9,438,720\n",
      "            Conv1d-8             [-1, 1536, 14]       9,438,720\n",
      "      CausalConv1d-9             [-1, 1536, 14]               0\n",
      "     CausalConv1d-10             [-1, 1536, 14]               0\n",
      "           Linear-11             [-1, 14, 1536]       2,360,832\n",
      "           Linear-12             [-1, 14, 1536]       2,360,832\n",
      "           Linear-13               [-1, 14, 16]          24,576\n",
      "           Linear-14               [-1, 14, 16]          24,576\n",
      "           Linear-15               [-1, 14, 16]          24,576\n",
      "           Linear-16               [-1, 14, 16]          24,576\n",
      "           Linear-17              [-1, 14, 768]       1,179,648\n",
      "           Linear-18              [-1, 14, 768]       1,179,648\n",
      "     SelectiveSSM-19              [-1, 14, 768]               0\n",
      "     SelectiveSSM-20              [-1, 14, 768]               0\n",
      "           Linear-21             [-1, 14, 3072]       2,359,296\n",
      "           Linear-22             [-1, 14, 3072]       2,359,296\n",
      "           Conv1d-23             [-1, 1536, 14]       9,438,720\n",
      "           Conv1d-24             [-1, 1536, 14]       9,438,720\n",
      "     CausalConv1d-25             [-1, 1536, 14]               0\n",
      "     CausalConv1d-26             [-1, 1536, 14]               0\n",
      "           Linear-27             [-1, 14, 1536]       2,360,832\n",
      "           Linear-28             [-1, 14, 1536]       2,360,832\n",
      "           Linear-29               [-1, 14, 16]          24,576\n",
      "           Linear-30               [-1, 14, 16]          24,576\n",
      "           Linear-31               [-1, 14, 16]          24,576\n",
      "           Linear-32               [-1, 14, 16]          24,576\n",
      "           Linear-33              [-1, 14, 768]       1,179,648\n",
      "           Linear-34              [-1, 14, 768]       1,179,648\n",
      "     SelectiveSSM-35              [-1, 14, 768]               0\n",
      "     SelectiveSSM-36              [-1, 14, 768]               0\n",
      "           Linear-37             [-1, 196, 768]         590,592\n",
      "  DirectionalScan-38             [-1, 196, 768]               0\n",
      "        LayerNorm-39             [-1, 196, 768]           1,536\n",
      "           Linear-40            [-1, 196, 3072]       2,362,368\n",
      "             GELU-41            [-1, 196, 3072]               0\n",
      "           Linear-42             [-1, 196, 768]       2,360,064\n",
      " VisionMambaBlock-43             [-1, 196, 768]               0\n",
      "        LayerNorm-44             [-1, 196, 768]           1,536\n",
      "           Linear-45             [-1, 14, 3072]       2,359,296\n",
      "           Linear-46             [-1, 14, 3072]       2,359,296\n",
      "           Conv1d-47             [-1, 1536, 14]       9,438,720\n",
      "           Conv1d-48             [-1, 1536, 14]       9,438,720\n",
      "     CausalConv1d-49             [-1, 1536, 14]               0\n",
      "     CausalConv1d-50             [-1, 1536, 14]               0\n",
      "           Linear-51             [-1, 14, 1536]       2,360,832\n",
      "           Linear-52             [-1, 14, 1536]       2,360,832\n",
      "           Linear-53               [-1, 14, 16]          24,576\n",
      "           Linear-54               [-1, 14, 16]          24,576\n",
      "           Linear-55               [-1, 14, 16]          24,576\n",
      "           Linear-56               [-1, 14, 16]          24,576\n",
      "           Linear-57              [-1, 14, 768]       1,179,648\n",
      "           Linear-58              [-1, 14, 768]       1,179,648\n",
      "     SelectiveSSM-59              [-1, 14, 768]               0\n",
      "     SelectiveSSM-60              [-1, 14, 768]               0\n",
      "           Linear-61             [-1, 14, 3072]       2,359,296\n",
      "           Linear-62             [-1, 14, 3072]       2,359,296\n",
      "           Conv1d-63             [-1, 1536, 14]       9,438,720\n",
      "           Conv1d-64             [-1, 1536, 14]       9,438,720\n",
      "     CausalConv1d-65             [-1, 1536, 14]               0\n",
      "     CausalConv1d-66             [-1, 1536, 14]               0\n",
      "           Linear-67             [-1, 14, 1536]       2,360,832\n",
      "           Linear-68             [-1, 14, 1536]       2,360,832\n",
      "           Linear-69               [-1, 14, 16]          24,576\n",
      "           Linear-70               [-1, 14, 16]          24,576\n",
      "           Linear-71               [-1, 14, 16]          24,576\n",
      "           Linear-72               [-1, 14, 16]          24,576\n",
      "           Linear-73              [-1, 14, 768]       1,179,648\n",
      "           Linear-74              [-1, 14, 768]       1,179,648\n",
      "     SelectiveSSM-75              [-1, 14, 768]               0\n",
      "     SelectiveSSM-76              [-1, 14, 768]               0\n",
      "           Linear-77             [-1, 196, 768]         590,592\n",
      "  DirectionalScan-78             [-1, 196, 768]               0\n",
      "        LayerNorm-79             [-1, 196, 768]           1,536\n",
      "           Linear-80            [-1, 196, 3072]       2,362,368\n",
      "             GELU-81            [-1, 196, 3072]               0\n",
      "           Linear-82             [-1, 196, 768]       2,360,064\n",
      " VisionMambaBlock-83             [-1, 196, 768]               0\n",
      "        LayerNorm-84             [-1, 196, 768]           1,536\n",
      "           Linear-85             [-1, 14, 3072]       2,359,296\n",
      "           Linear-86             [-1, 14, 3072]       2,359,296\n",
      "           Conv1d-87             [-1, 1536, 14]       9,438,720\n",
      "           Conv1d-88             [-1, 1536, 14]       9,438,720\n",
      "     CausalConv1d-89             [-1, 1536, 14]               0\n",
      "     CausalConv1d-90             [-1, 1536, 14]               0\n",
      "           Linear-91             [-1, 14, 1536]       2,360,832\n",
      "           Linear-92             [-1, 14, 1536]       2,360,832\n",
      "           Linear-93               [-1, 14, 16]          24,576\n",
      "           Linear-94               [-1, 14, 16]          24,576\n",
      "           Linear-95               [-1, 14, 16]          24,576\n",
      "           Linear-96               [-1, 14, 16]          24,576\n",
      "           Linear-97              [-1, 14, 768]       1,179,648\n",
      "           Linear-98              [-1, 14, 768]       1,179,648\n",
      "     SelectiveSSM-99              [-1, 14, 768]               0\n",
      "    SelectiveSSM-100              [-1, 14, 768]               0\n",
      "          Linear-101             [-1, 14, 3072]       2,359,296\n",
      "          Linear-102             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-103             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-104             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-105             [-1, 1536, 14]               0\n",
      "    CausalConv1d-106             [-1, 1536, 14]               0\n",
      "          Linear-107             [-1, 14, 1536]       2,360,832\n",
      "          Linear-108             [-1, 14, 1536]       2,360,832\n",
      "          Linear-109               [-1, 14, 16]          24,576\n",
      "          Linear-110               [-1, 14, 16]          24,576\n",
      "          Linear-111               [-1, 14, 16]          24,576\n",
      "          Linear-112               [-1, 14, 16]          24,576\n",
      "          Linear-113              [-1, 14, 768]       1,179,648\n",
      "          Linear-114              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-115              [-1, 14, 768]               0\n",
      "    SelectiveSSM-116              [-1, 14, 768]               0\n",
      "          Linear-117             [-1, 196, 768]         590,592\n",
      " DirectionalScan-118             [-1, 196, 768]               0\n",
      "       LayerNorm-119             [-1, 196, 768]           1,536\n",
      "          Linear-120            [-1, 196, 3072]       2,362,368\n",
      "            GELU-121            [-1, 196, 3072]               0\n",
      "          Linear-122             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-123             [-1, 196, 768]               0\n",
      "       LayerNorm-124             [-1, 196, 768]           1,536\n",
      "          Linear-125             [-1, 14, 3072]       2,359,296\n",
      "          Linear-126             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-127             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-128             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-129             [-1, 1536, 14]               0\n",
      "    CausalConv1d-130             [-1, 1536, 14]               0\n",
      "          Linear-131             [-1, 14, 1536]       2,360,832\n",
      "          Linear-132             [-1, 14, 1536]       2,360,832\n",
      "          Linear-133               [-1, 14, 16]          24,576\n",
      "          Linear-134               [-1, 14, 16]          24,576\n",
      "          Linear-135               [-1, 14, 16]          24,576\n",
      "          Linear-136               [-1, 14, 16]          24,576\n",
      "          Linear-137              [-1, 14, 768]       1,179,648\n",
      "          Linear-138              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-139              [-1, 14, 768]               0\n",
      "    SelectiveSSM-140              [-1, 14, 768]               0\n",
      "          Linear-141             [-1, 14, 3072]       2,359,296\n",
      "          Linear-142             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-143             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-144             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-145             [-1, 1536, 14]               0\n",
      "    CausalConv1d-146             [-1, 1536, 14]               0\n",
      "          Linear-147             [-1, 14, 1536]       2,360,832\n",
      "          Linear-148             [-1, 14, 1536]       2,360,832\n",
      "          Linear-149               [-1, 14, 16]          24,576\n",
      "          Linear-150               [-1, 14, 16]          24,576\n",
      "          Linear-151               [-1, 14, 16]          24,576\n",
      "          Linear-152               [-1, 14, 16]          24,576\n",
      "          Linear-153              [-1, 14, 768]       1,179,648\n",
      "          Linear-154              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-155              [-1, 14, 768]               0\n",
      "    SelectiveSSM-156              [-1, 14, 768]               0\n",
      "          Linear-157             [-1, 196, 768]         590,592\n",
      " DirectionalScan-158             [-1, 196, 768]               0\n",
      "       LayerNorm-159             [-1, 196, 768]           1,536\n",
      "          Linear-160            [-1, 196, 3072]       2,362,368\n",
      "            GELU-161            [-1, 196, 3072]               0\n",
      "          Linear-162             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-163             [-1, 196, 768]               0\n",
      "       LayerNorm-164             [-1, 196, 768]           1,536\n",
      "          Linear-165             [-1, 14, 3072]       2,359,296\n",
      "          Linear-166             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-167             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-168             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-169             [-1, 1536, 14]               0\n",
      "    CausalConv1d-170             [-1, 1536, 14]               0\n",
      "          Linear-171             [-1, 14, 1536]       2,360,832\n",
      "          Linear-172             [-1, 14, 1536]       2,360,832\n",
      "          Linear-173               [-1, 14, 16]          24,576\n",
      "          Linear-174               [-1, 14, 16]          24,576\n",
      "          Linear-175               [-1, 14, 16]          24,576\n",
      "          Linear-176               [-1, 14, 16]          24,576\n",
      "          Linear-177              [-1, 14, 768]       1,179,648\n",
      "          Linear-178              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-179              [-1, 14, 768]               0\n",
      "    SelectiveSSM-180              [-1, 14, 768]               0\n",
      "          Linear-181             [-1, 14, 3072]       2,359,296\n",
      "          Linear-182             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-183             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-184             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-185             [-1, 1536, 14]               0\n",
      "    CausalConv1d-186             [-1, 1536, 14]               0\n",
      "          Linear-187             [-1, 14, 1536]       2,360,832\n",
      "          Linear-188             [-1, 14, 1536]       2,360,832\n",
      "          Linear-189               [-1, 14, 16]          24,576\n",
      "          Linear-190               [-1, 14, 16]          24,576\n",
      "          Linear-191               [-1, 14, 16]          24,576\n",
      "          Linear-192               [-1, 14, 16]          24,576\n",
      "          Linear-193              [-1, 14, 768]       1,179,648\n",
      "          Linear-194              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-195              [-1, 14, 768]               0\n",
      "    SelectiveSSM-196              [-1, 14, 768]               0\n",
      "          Linear-197             [-1, 196, 768]         590,592\n",
      " DirectionalScan-198             [-1, 196, 768]               0\n",
      "       LayerNorm-199             [-1, 196, 768]           1,536\n",
      "          Linear-200            [-1, 196, 3072]       2,362,368\n",
      "            GELU-201            [-1, 196, 3072]               0\n",
      "          Linear-202             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-203             [-1, 196, 768]               0\n",
      "       LayerNorm-204             [-1, 196, 768]           1,536\n",
      "          Linear-205             [-1, 14, 3072]       2,359,296\n",
      "          Linear-206             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-207             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-208             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-209             [-1, 1536, 14]               0\n",
      "    CausalConv1d-210             [-1, 1536, 14]               0\n",
      "          Linear-211             [-1, 14, 1536]       2,360,832\n",
      "          Linear-212             [-1, 14, 1536]       2,360,832\n",
      "          Linear-213               [-1, 14, 16]          24,576\n",
      "          Linear-214               [-1, 14, 16]          24,576\n",
      "          Linear-215               [-1, 14, 16]          24,576\n",
      "          Linear-216               [-1, 14, 16]          24,576\n",
      "          Linear-217              [-1, 14, 768]       1,179,648\n",
      "          Linear-218              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-219              [-1, 14, 768]               0\n",
      "    SelectiveSSM-220              [-1, 14, 768]               0\n",
      "          Linear-221             [-1, 14, 3072]       2,359,296\n",
      "          Linear-222             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-223             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-224             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-225             [-1, 1536, 14]               0\n",
      "    CausalConv1d-226             [-1, 1536, 14]               0\n",
      "          Linear-227             [-1, 14, 1536]       2,360,832\n",
      "          Linear-228             [-1, 14, 1536]       2,360,832\n",
      "          Linear-229               [-1, 14, 16]          24,576\n",
      "          Linear-230               [-1, 14, 16]          24,576\n",
      "          Linear-231               [-1, 14, 16]          24,576\n",
      "          Linear-232               [-1, 14, 16]          24,576\n",
      "          Linear-233              [-1, 14, 768]       1,179,648\n",
      "          Linear-234              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-235              [-1, 14, 768]               0\n",
      "    SelectiveSSM-236              [-1, 14, 768]               0\n",
      "          Linear-237             [-1, 196, 768]         590,592\n",
      " DirectionalScan-238             [-1, 196, 768]               0\n",
      "       LayerNorm-239             [-1, 196, 768]           1,536\n",
      "          Linear-240            [-1, 196, 3072]       2,362,368\n",
      "            GELU-241            [-1, 196, 3072]               0\n",
      "          Linear-242             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-243             [-1, 196, 768]               0\n",
      "       LayerNorm-244             [-1, 196, 768]           1,536\n",
      "          Linear-245             [-1, 14, 3072]       2,359,296\n",
      "          Linear-246             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-247             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-248             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-249             [-1, 1536, 14]               0\n",
      "    CausalConv1d-250             [-1, 1536, 14]               0\n",
      "          Linear-251             [-1, 14, 1536]       2,360,832\n",
      "          Linear-252             [-1, 14, 1536]       2,360,832\n",
      "          Linear-253               [-1, 14, 16]          24,576\n",
      "          Linear-254               [-1, 14, 16]          24,576\n",
      "          Linear-255               [-1, 14, 16]          24,576\n",
      "          Linear-256               [-1, 14, 16]          24,576\n",
      "          Linear-257              [-1, 14, 768]       1,179,648\n",
      "          Linear-258              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-259              [-1, 14, 768]               0\n",
      "    SelectiveSSM-260              [-1, 14, 768]               0\n",
      "          Linear-261             [-1, 14, 3072]       2,359,296\n",
      "          Linear-262             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-263             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-264             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-265             [-1, 1536, 14]               0\n",
      "    CausalConv1d-266             [-1, 1536, 14]               0\n",
      "          Linear-267             [-1, 14, 1536]       2,360,832\n",
      "          Linear-268             [-1, 14, 1536]       2,360,832\n",
      "          Linear-269               [-1, 14, 16]          24,576\n",
      "          Linear-270               [-1, 14, 16]          24,576\n",
      "          Linear-271               [-1, 14, 16]          24,576\n",
      "          Linear-272               [-1, 14, 16]          24,576\n",
      "          Linear-273              [-1, 14, 768]       1,179,648\n",
      "          Linear-274              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-275              [-1, 14, 768]               0\n",
      "    SelectiveSSM-276              [-1, 14, 768]               0\n",
      "          Linear-277             [-1, 196, 768]         590,592\n",
      " DirectionalScan-278             [-1, 196, 768]               0\n",
      "       LayerNorm-279             [-1, 196, 768]           1,536\n",
      "          Linear-280            [-1, 196, 3072]       2,362,368\n",
      "            GELU-281            [-1, 196, 3072]               0\n",
      "          Linear-282             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-283             [-1, 196, 768]               0\n",
      "       LayerNorm-284             [-1, 196, 768]           1,536\n",
      "          Linear-285             [-1, 14, 3072]       2,359,296\n",
      "          Linear-286             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-287             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-288             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-289             [-1, 1536, 14]               0\n",
      "    CausalConv1d-290             [-1, 1536, 14]               0\n",
      "          Linear-291             [-1, 14, 1536]       2,360,832\n",
      "          Linear-292             [-1, 14, 1536]       2,360,832\n",
      "          Linear-293               [-1, 14, 16]          24,576\n",
      "          Linear-294               [-1, 14, 16]          24,576\n",
      "          Linear-295               [-1, 14, 16]          24,576\n",
      "          Linear-296               [-1, 14, 16]          24,576\n",
      "          Linear-297              [-1, 14, 768]       1,179,648\n",
      "          Linear-298              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-299              [-1, 14, 768]               0\n",
      "    SelectiveSSM-300              [-1, 14, 768]               0\n",
      "          Linear-301             [-1, 14, 3072]       2,359,296\n",
      "          Linear-302             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-303             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-304             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-305             [-1, 1536, 14]               0\n",
      "    CausalConv1d-306             [-1, 1536, 14]               0\n",
      "          Linear-307             [-1, 14, 1536]       2,360,832\n",
      "          Linear-308             [-1, 14, 1536]       2,360,832\n",
      "          Linear-309               [-1, 14, 16]          24,576\n",
      "          Linear-310               [-1, 14, 16]          24,576\n",
      "          Linear-311               [-1, 14, 16]          24,576\n",
      "          Linear-312               [-1, 14, 16]          24,576\n",
      "          Linear-313              [-1, 14, 768]       1,179,648\n",
      "          Linear-314              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-315              [-1, 14, 768]               0\n",
      "    SelectiveSSM-316              [-1, 14, 768]               0\n",
      "          Linear-317             [-1, 196, 768]         590,592\n",
      " DirectionalScan-318             [-1, 196, 768]               0\n",
      "       LayerNorm-319             [-1, 196, 768]           1,536\n",
      "          Linear-320            [-1, 196, 3072]       2,362,368\n",
      "            GELU-321            [-1, 196, 3072]               0\n",
      "          Linear-322             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-323             [-1, 196, 768]               0\n",
      "       LayerNorm-324             [-1, 196, 768]           1,536\n",
      "          Linear-325             [-1, 14, 3072]       2,359,296\n",
      "          Linear-326             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-327             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-328             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-329             [-1, 1536, 14]               0\n",
      "    CausalConv1d-330             [-1, 1536, 14]               0\n",
      "          Linear-331             [-1, 14, 1536]       2,360,832\n",
      "          Linear-332             [-1, 14, 1536]       2,360,832\n",
      "          Linear-333               [-1, 14, 16]          24,576\n",
      "          Linear-334               [-1, 14, 16]          24,576\n",
      "          Linear-335               [-1, 14, 16]          24,576\n",
      "          Linear-336               [-1, 14, 16]          24,576\n",
      "          Linear-337              [-1, 14, 768]       1,179,648\n",
      "          Linear-338              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-339              [-1, 14, 768]               0\n",
      "    SelectiveSSM-340              [-1, 14, 768]               0\n",
      "          Linear-341             [-1, 14, 3072]       2,359,296\n",
      "          Linear-342             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-343             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-344             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-345             [-1, 1536, 14]               0\n",
      "    CausalConv1d-346             [-1, 1536, 14]               0\n",
      "          Linear-347             [-1, 14, 1536]       2,360,832\n",
      "          Linear-348             [-1, 14, 1536]       2,360,832\n",
      "          Linear-349               [-1, 14, 16]          24,576\n",
      "          Linear-350               [-1, 14, 16]          24,576\n",
      "          Linear-351               [-1, 14, 16]          24,576\n",
      "          Linear-352               [-1, 14, 16]          24,576\n",
      "          Linear-353              [-1, 14, 768]       1,179,648\n",
      "          Linear-354              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-355              [-1, 14, 768]               0\n",
      "    SelectiveSSM-356              [-1, 14, 768]               0\n",
      "          Linear-357             [-1, 196, 768]         590,592\n",
      " DirectionalScan-358             [-1, 196, 768]               0\n",
      "       LayerNorm-359             [-1, 196, 768]           1,536\n",
      "          Linear-360            [-1, 196, 3072]       2,362,368\n",
      "            GELU-361            [-1, 196, 3072]               0\n",
      "          Linear-362             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-363             [-1, 196, 768]               0\n",
      "       LayerNorm-364             [-1, 196, 768]           1,536\n",
      "          Linear-365             [-1, 14, 3072]       2,359,296\n",
      "          Linear-366             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-367             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-368             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-369             [-1, 1536, 14]               0\n",
      "    CausalConv1d-370             [-1, 1536, 14]               0\n",
      "          Linear-371             [-1, 14, 1536]       2,360,832\n",
      "          Linear-372             [-1, 14, 1536]       2,360,832\n",
      "          Linear-373               [-1, 14, 16]          24,576\n",
      "          Linear-374               [-1, 14, 16]          24,576\n",
      "          Linear-375               [-1, 14, 16]          24,576\n",
      "          Linear-376               [-1, 14, 16]          24,576\n",
      "          Linear-377              [-1, 14, 768]       1,179,648\n",
      "          Linear-378              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-379              [-1, 14, 768]               0\n",
      "    SelectiveSSM-380              [-1, 14, 768]               0\n",
      "          Linear-381             [-1, 14, 3072]       2,359,296\n",
      "          Linear-382             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-383             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-384             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-385             [-1, 1536, 14]               0\n",
      "    CausalConv1d-386             [-1, 1536, 14]               0\n",
      "          Linear-387             [-1, 14, 1536]       2,360,832\n",
      "          Linear-388             [-1, 14, 1536]       2,360,832\n",
      "          Linear-389               [-1, 14, 16]          24,576\n",
      "          Linear-390               [-1, 14, 16]          24,576\n",
      "          Linear-391               [-1, 14, 16]          24,576\n",
      "          Linear-392               [-1, 14, 16]          24,576\n",
      "          Linear-393              [-1, 14, 768]       1,179,648\n",
      "          Linear-394              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-395              [-1, 14, 768]               0\n",
      "    SelectiveSSM-396              [-1, 14, 768]               0\n",
      "          Linear-397             [-1, 196, 768]         590,592\n",
      " DirectionalScan-398             [-1, 196, 768]               0\n",
      "       LayerNorm-399             [-1, 196, 768]           1,536\n",
      "          Linear-400            [-1, 196, 3072]       2,362,368\n",
      "            GELU-401            [-1, 196, 3072]               0\n",
      "          Linear-402             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-403             [-1, 196, 768]               0\n",
      "       LayerNorm-404             [-1, 196, 768]           1,536\n",
      "          Linear-405             [-1, 14, 3072]       2,359,296\n",
      "          Linear-406             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-407             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-408             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-409             [-1, 1536, 14]               0\n",
      "    CausalConv1d-410             [-1, 1536, 14]               0\n",
      "          Linear-411             [-1, 14, 1536]       2,360,832\n",
      "          Linear-412             [-1, 14, 1536]       2,360,832\n",
      "          Linear-413               [-1, 14, 16]          24,576\n",
      "          Linear-414               [-1, 14, 16]          24,576\n",
      "          Linear-415               [-1, 14, 16]          24,576\n",
      "          Linear-416               [-1, 14, 16]          24,576\n",
      "          Linear-417              [-1, 14, 768]       1,179,648\n",
      "          Linear-418              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-419              [-1, 14, 768]               0\n",
      "    SelectiveSSM-420              [-1, 14, 768]               0\n",
      "          Linear-421             [-1, 14, 3072]       2,359,296\n",
      "          Linear-422             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-423             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-424             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-425             [-1, 1536, 14]               0\n",
      "    CausalConv1d-426             [-1, 1536, 14]               0\n",
      "          Linear-427             [-1, 14, 1536]       2,360,832\n",
      "          Linear-428             [-1, 14, 1536]       2,360,832\n",
      "          Linear-429               [-1, 14, 16]          24,576\n",
      "          Linear-430               [-1, 14, 16]          24,576\n",
      "          Linear-431               [-1, 14, 16]          24,576\n",
      "          Linear-432               [-1, 14, 16]          24,576\n",
      "          Linear-433              [-1, 14, 768]       1,179,648\n",
      "          Linear-434              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-435              [-1, 14, 768]               0\n",
      "    SelectiveSSM-436              [-1, 14, 768]               0\n",
      "          Linear-437             [-1, 196, 768]         590,592\n",
      " DirectionalScan-438             [-1, 196, 768]               0\n",
      "       LayerNorm-439             [-1, 196, 768]           1,536\n",
      "          Linear-440            [-1, 196, 3072]       2,362,368\n",
      "            GELU-441            [-1, 196, 3072]               0\n",
      "          Linear-442             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-443             [-1, 196, 768]               0\n",
      "       LayerNorm-444             [-1, 196, 768]           1,536\n",
      "          Linear-445             [-1, 14, 3072]       2,359,296\n",
      "          Linear-446             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-447             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-448             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-449             [-1, 1536, 14]               0\n",
      "    CausalConv1d-450             [-1, 1536, 14]               0\n",
      "          Linear-451             [-1, 14, 1536]       2,360,832\n",
      "          Linear-452             [-1, 14, 1536]       2,360,832\n",
      "          Linear-453               [-1, 14, 16]          24,576\n",
      "          Linear-454               [-1, 14, 16]          24,576\n",
      "          Linear-455               [-1, 14, 16]          24,576\n",
      "          Linear-456               [-1, 14, 16]          24,576\n",
      "          Linear-457              [-1, 14, 768]       1,179,648\n",
      "          Linear-458              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-459              [-1, 14, 768]               0\n",
      "    SelectiveSSM-460              [-1, 14, 768]               0\n",
      "          Linear-461             [-1, 14, 3072]       2,359,296\n",
      "          Linear-462             [-1, 14, 3072]       2,359,296\n",
      "          Conv1d-463             [-1, 1536, 14]       9,438,720\n",
      "          Conv1d-464             [-1, 1536, 14]       9,438,720\n",
      "    CausalConv1d-465             [-1, 1536, 14]               0\n",
      "    CausalConv1d-466             [-1, 1536, 14]               0\n",
      "          Linear-467             [-1, 14, 1536]       2,360,832\n",
      "          Linear-468             [-1, 14, 1536]       2,360,832\n",
      "          Linear-469               [-1, 14, 16]          24,576\n",
      "          Linear-470               [-1, 14, 16]          24,576\n",
      "          Linear-471               [-1, 14, 16]          24,576\n",
      "          Linear-472               [-1, 14, 16]          24,576\n",
      "          Linear-473              [-1, 14, 768]       1,179,648\n",
      "          Linear-474              [-1, 14, 768]       1,179,648\n",
      "    SelectiveSSM-475              [-1, 14, 768]               0\n",
      "    SelectiveSSM-476              [-1, 14, 768]               0\n",
      "          Linear-477             [-1, 196, 768]         590,592\n",
      " DirectionalScan-478             [-1, 196, 768]               0\n",
      "       LayerNorm-479             [-1, 196, 768]           1,536\n",
      "          Linear-480            [-1, 196, 3072]       2,362,368\n",
      "            GELU-481            [-1, 196, 3072]               0\n",
      "          Linear-482             [-1, 196, 768]       2,360,064\n",
      "VisionMambaBlock-483             [-1, 196, 768]               0\n",
      "       LayerNorm-484                  [-1, 768]           1,536\n",
      "          Linear-485                 [-1, 1000]         769,000\n",
      "================================================================\n",
      "Total params: 803,761,384\n",
      "Trainable params: 803,761,384\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 243.81\n",
      "Params size (MB): 3066.11\n",
      "Estimated Total Size (MB): 3310.49\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Layer Dimension Flow:\n",
      "+---------------+------------------+------------------+\n",
      "| Layer         | Input Shape      | Output Shape     |\n",
      "+===============+==================+==================+\n",
      "| Input         | -                | (1, 3, 224, 224) |\n",
      "+---------------+------------------+------------------+\n",
      "| PatchEmbed    | (1, 3, 224, 224) | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_1  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_2  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_3  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_4  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_5  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_6  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_7  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_8  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_9  | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_10 | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_11 | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| MambaBlock_12 | (1, 196, 768)    | (1, 196, 768)    |\n",
      "+---------------+------------------+------------------+\n",
      "| Norm+Head     | (1, 196, 768)    | (1, 1000)        |\n",
      "+---------------+------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "print_model_summary(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
